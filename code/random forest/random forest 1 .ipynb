{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "830cf826-1aa5-467a-a8c3-a804fac2e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a472b634-2d7d-4269-af1b-bb8f60e36be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.columns = df.columns.str.strip()  # Clean column names\n",
    "    \n",
    "    # Check if 'Disease' column exists\n",
    "    if 'Disease' not in df.columns:\n",
    "        raise KeyError(\"Column 'Disease' not found in dataset.\")\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('Disease', axis=1)\n",
    "    y = df['Disease']\n",
    "    \n",
    "    # Define numerical and categorical columns\n",
    "    numerical_cols = ['Dosage (mg)']\n",
    "    categorical_cols = [col for col in X.columns if col != 'Dosage (mg)']\n",
    "    \n",
    "    # Create preprocessing pipelines\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Apply transformations\n",
    "    X_preprocessed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    return X_preprocessed, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0180c783-e991-49b1-87a4-4d1e3be46f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "10d869da-3eac-4d3d-9509-f174dff21bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "839b39dc-47b8-4284-9aa1-fbb9fed1db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X_val, y_val, dataset_type=\"Validation\"):\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    report = classification_report(y_val, y_pred)\n",
    "    \n",
    "    print(f\"{dataset_type} Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"{dataset_type} Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6f5ca2fd-97f5-4acd-962c-6c26d78da9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display feature importance\n",
    "def display_feature_importance(model, feature_names):\n",
    "    importances = model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "    print(feature_importance_df.sort_values(by='Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0c93535a-9e4d-416a-90bd-0ec1791f1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_with_regularization(\n",
    "    data_path, target_column, test_size=0.2, cv_folds=5,\n",
    "    n_estimators=100, max_depth=10, min_samples_split=10,\n",
    "    min_samples_leaf=4, random_state=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a Random Forest model with pruning and cross-validation to avoid overfitting.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the dataset\n",
    "    X, y = load_and_preprocess_data(data_path)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Initialize the Random Forest Classifier with regularization parameters\n",
    "    rf_classifier = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(\n",
    "        rf_classifier, X_train, y_train, cv=cv_folds\n",
    "    )\n",
    "    cv_accuracy = cv_scores.mean() * 100\n",
    "    \n",
    "    # Train the model\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "    classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Prepare results\n",
    "    results = {\n",
    "        'cv_accuracy': cv_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'classification_report': classification_rep\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27299bff-1ae7-4fd2-b3f3-0fd91e746432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main execution function to handle everything\n",
    "# def main():\n",
    "#     # File paths of the datasets\n",
    "#     train_file_path = 'synthetic_detailed_ayurveda_dataset.csv'  # Detailed dataset for training\n",
    "#     test_file_path = 'synthetic_ayurveda_dataset.csv'  # Simpler dataset for validation/testing\n",
    "    \n",
    "#     # Step 1: Load and preprocess both datasets\n",
    "#     df_train = load_and_preprocess_data(train_file_path)\n",
    "#     df_test = load_and_preprocess_data(test_file_path)\n",
    "    \n",
    "#     # Step 2: Split data (training from detailed, testing from simpler dataset)\n",
    "#     X_train, X_test, y_train, y_test = split_data(df_train, df_test, target_column='Disease')\n",
    "    \n",
    "#     # Step 3: Train Random Forest model using the training dataset\n",
    "#     rf_classifier = train_random_forest(X_train, y_train)\n",
    "    \n",
    "#     # Step 4: Evaluate model on the validation/test dataset\n",
    "#     evaluate_model(rf_classifier, X_test, y_test, dataset_type=\"Test\")\n",
    "    \n",
    "#     # Step 5: Display feature importance from the trained model\n",
    "#     display_feature_importance(rf_classifier, X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a1d3440e-4f01-405a-bf50-511acdeb99fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load and preprocess data\n",
    "    train_file_path = 'detailed_dataset.csv'\n",
    "    test_file_path = 'synthetic_ayurveda_dataset.csv'\n",
    "    \n",
    "    X_train, y_train = load_and_preprocess_data(train_file_path)\n",
    "    X_test, y_test = load_and_preprocess_data(test_file_path)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train Random Forest model\n",
    "    rf_classifier = train_random_forest(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evaluate_model(rf_classifier, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c7bedb94-a318-4bce-8522-6eab40adb7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: 11.70%\n",
      "Test Accuracy: 10.80%\n",
      "Test Classification Report:\n",
      "{'Arthritis': {'precision': 0.125, 'recall': 0.06862745098039216, 'f1-score': 0.08860759493670886, 'support': 102}, 'Diabetes': {'precision': 0.0851063829787234, 'recall': 0.04040404040404041, 'f1-score': 0.054794520547945216, 'support': 99}, 'Digestive Disorders': {'precision': 0.09042553191489362, 'recall': 0.14912280701754385, 'f1-score': 0.11258278145695365, 'support': 114}, 'Hypertension': {'precision': 0.10404624277456648, 'recall': 0.1651376146788991, 'f1-score': 0.1276595744680851, 'support': 109}, 'Inflammation': {'precision': 0.14864864864864866, 'recall': 0.08661417322834646, 'f1-score': 0.10945273631840798, 'support': 127}, 'Liver Disorders': {'precision': 0.1111111111111111, 'recall': 0.08461538461538462, 'f1-score': 0.09606986899563319, 'support': 130}, 'Mental Stress': {'precision': 0.11235955056179775, 'recall': 0.18867924528301888, 'f1-score': 0.14084507042253522, 'support': 106}, 'Respiratory Issues': {'precision': 0.13740458015267176, 'recall': 0.16981132075471697, 'f1-score': 0.1518987341772152, 'support': 106}, 'Skin Diseases': {'precision': 0.037037037037037035, 'recall': 0.018691588785046728, 'f1-score': 0.024844720496894408, 'support': 107}, 'accuracy': 0.108, 'macro avg': {'precision': 0.1056821205754944, 'recall': 0.10796706952748769, 'f1-score': 0.10075062242448654, 'support': 1000}, 'weighted avg': {'precision': 0.10658586665713878, 'recall': 0.108, 'f1-score': 0.10129077178351624, 'support': 1000}}\n"
     ]
    }
   ],
   "source": [
    "results = random_forest_with_regularization(\n",
    "    data_path='synthetic_detailed_ayurveda_dataset.csv',\n",
    "    target_column='Disease',\n",
    "    test_size=0.2,\n",
    "    cv_folds=5,\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(f\"Cross-Validation Accuracy: {results['cv_accuracy']:.2f}%\")\n",
    "print(f\"Test Accuracy: {results['test_accuracy']:.2f}%\")\n",
    "print(\"Test Classification Report:\")\n",
    "print(results['classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe89c2-10e2-48b7-8374-8af114a2c09c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
